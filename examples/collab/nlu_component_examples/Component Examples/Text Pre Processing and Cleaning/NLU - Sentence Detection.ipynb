{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"NLU - Sentence Detection.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMZjjgz6AAopcyWI7YKIBm3"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"ranKMTS37jDN","colab_type":"text"},"source":["# Detect sentences with NLU \n","\n","Detecting sentences is a common problen when working with text data.       \n","The NLU Sentence Detector will find the beginning and end of each sentence for every row in your dataset.\n","\n","\n","## 1. Install NLU and Java 8"]},{"cell_type":"code","metadata":{"id":"c0qqCrWszHqD","colab_type":"code","colab":{}},"source":["import os\n","! apt-get update -qq > /dev/null   \n","# Install java\n","! apt-get install -y openjdk-8-jdk-headless -qq > /dev/null\n","os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n","os.environ[\"PATH\"] = os.environ[\"JAVA_HOME\"] + \"/bin:\" + os.environ[\"PATH\"]\n","! pip install nlu > /dev/null    "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"U901gdUaAdz0","colab_type":"text"},"source":["# 2. Load the Sentence Detector and predict the sentences"]},{"cell_type":"code","metadata":{"id":"j7CAYGm97gHm","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":326},"executionInfo":{"status":"ok","timestamp":1600008746831,"user_tz":-120,"elapsed":12815,"user":{"displayName":"Christian Kasim Loan","photoUrl":"","userId":"14469489166467359317"}},"outputId":"e7d08975-9e22-4c96-94be-09614bafd253"},"source":["import nlu\n","sentence_pipe = nlu.load('sentence_detector')\n","sentence_pipe.predict('NLU can detect things. Like beginning and endings of sentences. It can also do much more!', output_level ='sentence')  "],"execution_count":null,"outputs":[{"output_type":"stream","text":["ner_dl_sentence download started this may take some time.\n","Approximate size to download 13.3 MB\n","[OK!]\n","pos_anc download started this may take some time.\n","Approximate size to download 4.3 MB\n","[OK!]\n","glove_100d download started this may take some time.\n","Approximate size to download 145.3 MB\n","[OK!]\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>pos</th>\n","      <th>word_embeddings</th>\n","      <th>sentence</th>\n","      <th>ner_tag</th>\n","      <th>entities</th>\n","    </tr>\n","    <tr>\n","      <th>origin_index</th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>[NNP, MD, VB, NNS, ., IN, VBG, CC, NNS, IN, NN...</td>\n","      <td>[[0.4970400035381317, -0.013454999774694443, 0...</td>\n","      <td>NLU can detect things.</td>\n","      <td>[sent, sent]</td>\n","      <td>[Like, It]</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>[NNP, MD, VB, NNS, ., IN, VBG, CC, NNS, IN, NN...</td>\n","      <td>[[0.4970400035381317, -0.013454999774694443, 0...</td>\n","      <td>Like beginning and endings of sentences.</td>\n","      <td>[sent, sent]</td>\n","      <td>[Like, It]</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>[NNP, MD, VB, NNS, ., IN, VBG, CC, NNS, IN, NN...</td>\n","      <td>[[0.4970400035381317, -0.013454999774694443, 0...</td>\n","      <td>It can also do much more!</td>\n","      <td>[sent, sent]</td>\n","      <td>[Like, It]</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                                            pos  ...    entities\n","origin_index                                                     ...            \n","0             [NNP, MD, VB, NNS, ., IN, VBG, CC, NNS, IN, NN...  ...  [Like, It]\n","0             [NNP, MD, VB, NNS, ., IN, VBG, CC, NNS, IN, NN...  ...  [Like, It]\n","0             [NNP, MD, VB, NNS, ., IN, VBG, CC, NNS, IN, NN...  ...  [Like, It]\n","\n","[3 rows x 5 columns]"]},"metadata":{"tags":[]},"execution_count":5}]},{"cell_type":"markdown","metadata":{"id":"ouB-AmiW_WHF","colab_type":"text"},"source":["# 3.  Lets configure our pipeline.\n","\n","By calling pipe.print_info() we can can see all configurable parameters for every component in this NLU pipeline.     \n","We can simply copy paste the outputs of print_info() and configure our pipe.      \n"]},{"cell_type":"code","metadata":{"id":"mP6tnVnB-t8k","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":632},"executionInfo":{"status":"ok","timestamp":1600009202747,"user_tz":-120,"elapsed":778,"user":{"displayName":"Christian Kasim Loan","photoUrl":"","userId":"14469489166467359317"}},"outputId":"d9735153-7b11-4c74-ad4e-fa671e9349d7"},"source":["sentence_pipe.print_info()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["The following parameters are configurable for this NLU pipeline (You can copy paste the examples) :\n",">>> pipe['named_entity_recognizer_dl'] has settable params:\n","pipe['named_entity_recognizer_dl'].setIncludeConfidence(False)  | Info: whether to include confidence scores in annotation metadata | Currently set to : False\n","pipe['named_entity_recognizer_dl'].setLazyAnnotator(False)  | Info: Whether this AnnotatorModel acts as lazy in RecursivePipelines | Currently set to : False\n","pipe['named_entity_recognizer_dl'].setBatchSize(4)   | Info: Size of every batch. | Currently set to : 4\n","pipe['named_entity_recognizer_dl'].setClasses(['O', 'B-sent', 'X'])  | Info: get the tags used to trained this NerDLModel | Currently set to : ['O', 'B-sent', 'X']\n","pipe['named_entity_recognizer_dl'].setStorageRef('glove_100d')  | Info: unique reference name for identification | Currently set to : glove_100d\n",">>> pipe['pos'] has settable params:\n","pipe['pos'].setLazyAnnotator(False)                  | Info: Whether this AnnotatorModel acts as lazy in RecursivePipelines | Currently set to : False\n",">>> pipe['default_tokenizer'] has settable params:\n","pipe['default_tokenizer'].setLazyAnnotator(False)    | Info: Whether this AnnotatorModel acts as lazy in RecursivePipelines | Currently set to : False\n","pipe['default_tokenizer'].setTargetPattern('\\S+')    | Info: pattern to grab from text as token candidates. Defaults \\S+ | Currently set to : \\S+\n","pipe['default_tokenizer'].setContextChars(['.', ',', ';', ':', '!', '?', '*', '-', '(', ')', '\"', \"'\"])  | Info: character list used to separate from token boundaries | Currently set to : ['.', ',', ';', ':', '!', '?', '*', '-', '(', ')', '\"', \"'\"]\n","pipe['default_tokenizer'].setCaseSensitiveExceptions(True)  | Info: Whether to care for case sensitiveness in exceptions | Currently set to : True\n","pipe['default_tokenizer'].setMinLength(0)            | Info: Set the minimum allowed legth for each token | Currently set to : 0\n","pipe['default_tokenizer'].setMaxLength(99999)        | Info: Set the maximum allowed legth for each token | Currently set to : 99999\n",">>> pipe['sentence_detector'] has settable params:\n","pipe['sentence_detector'].setLazyAnnotator(False)    | Info: Whether this AnnotatorModel acts as lazy in RecursivePipelines | Currently set to : False\n","pipe['sentence_detector'].setUseAbbreviations(True)  | Info: whether to apply abbreviations at sentence detection | Currently set to : True\n","pipe['sentence_detector'].setDetectLists(True)       | Info: whether detect lists during sentence detection | Currently set to : True\n","pipe['sentence_detector'].setUseCustomBoundsOnly(False)  | Info: Only utilize custom bounds in sentence detection | Currently set to : False\n","pipe['sentence_detector'].setCustomBounds([])        | Info: characters used to explicitly mark sentence bounds | Currently set to : []\n","pipe['sentence_detector'].setExplodeSentences(False)  | Info: whether to explode each sentence into a different row, for better parallelization. Defaults to false. | Currently set to : False\n","pipe['sentence_detector'].setMinLength(0)            | Info: Set the minimum allowed length for each sentence. | Currently set to : 0\n","pipe['sentence_detector'].setMaxLength(3)            | Info: Set the maximum allowed length for each sentence | Currently set to : 3\n",">>> pipe['glove'] has settable params:\n","pipe['glove'].setIncludeStorage(True)                | Info: whether to include indexed storage in trained model | Currently set to : True\n","pipe['glove'].setLazyAnnotator(False)                | Info: Whether this AnnotatorModel acts as lazy in RecursivePipelines | Currently set to : False\n","pipe['glove'].setCaseSensitive(False)                | Info: whether to ignore case in tokens for embeddings matching | Currently set to : False\n","pipe['glove'].setDimension(100)                      | Info: Number of embedding dimensions | Currently set to : 100\n","pipe['glove'].setStorageRef('glove_100d')            | Info: unique reference name for identification | Currently set to : glove_100d\n",">>> pipe['NerToChunkConverter'] has settable params:\n","pipe['NerToChunkConverter'].setLazyAnnotator(False)  | Info: Whether this AnnotatorModel acts as lazy in RecursivePipelines | Currently set to : False\n",">>> pipe['document_assembler'] has settable params:\n","pipe['document_assembler'].setCleanupMode('shrink')  | Info: possible values: disabled, inplace, inplace_full, shrink, shrink_full, each, each_full, delete_full | Currently set to : shrink\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"0dFUpqba_w1d","colab_type":"text"},"source":["# 3.1 Lets configure our Sentence Detector to only accept sentences of length minimum 5"]},{"cell_type":"code","metadata":{"id":"3ubokWw18cY1","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":326},"executionInfo":{"status":"ok","timestamp":1600009476876,"user_tz":-120,"elapsed":11970,"user":{"displayName":"Christian Kasim Loan","photoUrl":"","userId":"14469489166467359317"}},"outputId":"6d9e58c0-90d1-47e1-f0d8-7024c50b7d70"},"source":["sentence_pipe = nlu.load('sentence_detector')\n","sentence_pipe['sentence_detector'].setMinLength(5)\n","sentence_pipe.predict('NLU can detect things. Like beginning and endings of sentences. It can also do much more!', output_level ='sentence')  "],"execution_count":null,"outputs":[{"output_type":"stream","text":["ner_dl_sentence download started this may take some time.\n","Approximate size to download 13.3 MB\n","[OK!]\n","pos_anc download started this may take some time.\n","Approximate size to download 4.3 MB\n","[OK!]\n","glove_100d download started this may take some time.\n","Approximate size to download 145.3 MB\n","[OK!]\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>pos</th>\n","      <th>word_embeddings</th>\n","      <th>sentence</th>\n","      <th>ner_tag</th>\n","      <th>entities</th>\n","    </tr>\n","    <tr>\n","      <th>origin_index</th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>[NNP, MD, VB, NNS, ., IN, VBG, CC, NNS, IN, NN...</td>\n","      <td>[[0.4970400035381317, -0.013454999774694443, 0...</td>\n","      <td>NLU can detect things.</td>\n","      <td>[sent, sent]</td>\n","      <td>[Like, It]</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>[NNP, MD, VB, NNS, ., IN, VBG, CC, NNS, IN, NN...</td>\n","      <td>[[0.4970400035381317, -0.013454999774694443, 0...</td>\n","      <td>Like beginning and endings of sentences.</td>\n","      <td>[sent, sent]</td>\n","      <td>[Like, It]</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>[NNP, MD, VB, NNS, ., IN, VBG, CC, NNS, IN, NN...</td>\n","      <td>[[0.4970400035381317, -0.013454999774694443, 0...</td>\n","      <td>It can also do much more!</td>\n","      <td>[sent, sent]</td>\n","      <td>[Like, It]</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                                            pos  ...    entities\n","origin_index                                                     ...            \n","0             [NNP, MD, VB, NNS, ., IN, VBG, CC, NNS, IN, NN...  ...  [Like, It]\n","0             [NNP, MD, VB, NNS, ., IN, VBG, CC, NNS, IN, NN...  ...  [Like, It]\n","0             [NNP, MD, VB, NNS, ., IN, VBG, CC, NNS, IN, NN...  ...  [Like, It]\n","\n","[3 rows x 5 columns]"]},"metadata":{"tags":[]},"execution_count":14}]},{"cell_type":"code","metadata":{"id":"DFi8VWxq88c-","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]}]}