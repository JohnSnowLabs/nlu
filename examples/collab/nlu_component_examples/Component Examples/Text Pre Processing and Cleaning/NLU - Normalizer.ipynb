{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"NLU - Normalizer.ipynb","provenance":[{"file_id":"1pgqoRJ6yGWbTLWdLnRvwG5DLSU3rxuMq","timestamp":1599401652794},{"file_id":"1JrlfuV2jNGTdOXvaWIoHTSf6BscDMkN7","timestamp":1599401257319},{"file_id":"1svpqtC3cY6JnRGeJngIPl2raqxdowpyi","timestamp":1599400881246},{"file_id":"1tW833T3HS8F5Lvn6LgeDd5LW5226syKN","timestamp":1599398724652},{"file_id":"1CYzHfQyFCdvIOVO2Z5aggVI9c0hDEOrw","timestamp":1599354735581}],"collapsed_sections":[],"authorship_tag":"ABX9TyN2l0+ZX1hYi16n/hpLQr4M"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"rBXrqlGEYA8G","colab_type":"text"},"source":["# Normalziing with NLU \n","\n","The Normalizer cleans text data from dirty characters, lowercases it by default and removes punctuation.       \n","\n","### Removes all dirty characters and from text following a regex pattern.    \n","- Dirty characters are things like !@#$%^&*()?>< etc..\n","- Useful for reducing dimension/variance of your data since fewer symbols will occur\n","- Useful for cleaning tweets \n","- Matches slangs\n","- Language independent \n","- You can use a regex pattern to specify which tokens will *not* be removed.  \n","\n","I.e the pattern [a-z] matches all characters from a,b,c... to x,y,z. It will throw\n","```\n","pipe['normalizer'].setCleanupPatterns('[a-z]') \n","```\n","\n","\n","# 1. Install Java and NLU"]},{"cell_type":"code","metadata":{"id":"M2-GiYL6xurJ","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1600189937556,"user_tz":-120,"elapsed":63437,"user":{"displayName":"Christian Kasim Loan","photoUrl":"","userId":"14469489166467359317"}}},"source":["\n","import os\n","! apt-get update -qq > /dev/null   \n","# Install java\n","! apt-get install -y openjdk-8-jdk-headless -qq > /dev/null\n","os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n","os.environ[\"PATH\"] = os.environ[\"JAVA_HOME\"] + \"/bin:\" + os.environ[\"PATH\"]\n","! pip install nlu  > /dev/null    "],"execution_count":1,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"N_CL8HZ8Ydry","colab_type":"text"},"source":["## 2. Load Model and normalize sample string"]},{"cell_type":"code","metadata":{"id":"pmpZSNvGlyZQ","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":111},"executionInfo":{"status":"ok","timestamp":1600189968778,"user_tz":-120,"elapsed":94646,"user":{"displayName":"Christian Kasim Loan","photoUrl":"","userId":"14469489166467359317"}},"outputId":"8e6f04b1-1409-4622-97d6-d7630b8e3c6d"},"source":["import nlu \n","\n","\n","nlu.load('norm').predict('@CKL_IT says: that #normalizers are pretty useful to clean #structured_strings in #NLU like tweets')"],"execution_count":2,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>normalized</th>\n","      <th>sentence</th>\n","    </tr>\n","    <tr>\n","      <th>origin_index</th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>[CKLIT, says, that, normalizers, are, pretty, ...</td>\n","      <td>@CKL_IT says: that #normalizers are pretty use...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                                     normalized                                           sentence\n","origin_index                                                                                                      \n","0             [CKLIT, says, that, normalizers, are, pretty, ...  @CKL_IT says: that #normalizers are pretty use..."]},"metadata":{"tags":[]},"execution_count":2}]},{"cell_type":"markdown","metadata":{"id":"fvWCtpHCwOYz","colab_type":"text"},"source":["## 2. Configure the normalizer with custom parameters\n","Use the pipe.print_info() to see all configurable parameters and infos about them for every NLU component in the pipeline pipeline.     \n","Even tough only 'norm' is loaded, many NLU component dependencies are automatically loaded into the pipeline and also configurable. \n","\n","\n","By default the normalizer will set all tokens to lower case.     \n","Lets change that"]},{"cell_type":"code","metadata":{"id":"j2ZZZvr1uGpx","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":111},"executionInfo":{"status":"ok","timestamp":1600189971697,"user_tz":-120,"elapsed":97554,"user":{"displayName":"Christian Kasim Loan","photoUrl":"","userId":"14469489166467359317"}},"outputId":"9f3333f0-5617-4753-d890-e615a1d14b03"},"source":["pipe = nlu.load('norm')\n","pipe.predict('LOWERCASE BY DEFAULT')"],"execution_count":3,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>normalized</th>\n","      <th>sentence</th>\n","    </tr>\n","    <tr>\n","      <th>origin_index</th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>[LOWERCASE, BY, DEFAULT]</td>\n","      <td>LOWERCASE BY DEFAULT</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                            normalized              sentence\n","origin_index                                                \n","0             [LOWERCASE, BY, DEFAULT]  LOWERCASE BY DEFAULT"]},"metadata":{"tags":[]},"execution_count":3}]},{"cell_type":"markdown","metadata":{"id":"v4qbFCJ1Ao6I","colab_type":"text"},"source":["### 2.1 Print all parameters for all NLU components in the pipeline \n"]},{"cell_type":"code","metadata":{"id":"TN59JZIBtKC8","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":394},"executionInfo":{"status":"ok","timestamp":1600189971699,"user_tz":-120,"elapsed":97546,"user":{"displayName":"Christian Kasim Loan","photoUrl":"","userId":"14469489166467359317"}},"outputId":"1de2d32a-635b-4f27-9e8e-63fc086a002c"},"source":["pipe.print_info()\n"],"execution_count":4,"outputs":[{"output_type":"stream","text":["The following parameters are configurable for this NLU pipeline (You can copy paste the examples) :\n",">>> pipe['normalizer'] has settable params:\n","pipe['normalizer'].setCleanupPatterns(['[^\\\\pL+]'])  | Info: normalization regex patterns which match will be removed from token | Currently set to : ['[^\\\\pL+]']\n","pipe['normalizer'].setLowercase(False)               | Info: whether to convert strings to lowercase | Currently set to : False\n","pipe['normalizer'].setSlangMatchCase(False)          | Info: whether or not to be case sensitive to match slangs. Defaults to false. | Currently set to : False\n",">>> pipe['default_tokenizer'] has settable params:\n","pipe['default_tokenizer'].setTargetPattern('\\S+')    | Info: pattern to grab from text as token candidates. Defaults \\S+ | Currently set to : \\S+\n","pipe['default_tokenizer'].setContextChars(['.', ',', ';', ':', '!', '?', '*', '-', '(', ')', '\"', \"'\"])  | Info: character list used to separate from token boundaries | Currently set to : ['.', ',', ';', ':', '!', '?', '*', '-', '(', ')', '\"', \"'\"]\n","pipe['default_tokenizer'].setCaseSensitiveExceptions(True)  | Info: Whether to care for case sensitiveness in exceptions | Currently set to : True\n","pipe['default_tokenizer'].setMinLength(0)            | Info: Set the minimum allowed legth for each token | Currently set to : 0\n","pipe['default_tokenizer'].setMaxLength(99999)        | Info: Set the maximum allowed legth for each token | Currently set to : 99999\n",">>> pipe['sentence_detector'] has settable params:\n","pipe['sentence_detector'].setUseAbbreviations(True)  | Info: whether to apply abbreviations at sentence detection | Currently set to : True\n","pipe['sentence_detector'].setDetectLists(True)       | Info: whether detect lists during sentence detection | Currently set to : True\n","pipe['sentence_detector'].setUseCustomBoundsOnly(False)  | Info: Only utilize custom bounds in sentence detection | Currently set to : False\n","pipe['sentence_detector'].setCustomBounds([])        | Info: characters used to explicitly mark sentence bounds | Currently set to : []\n","pipe['sentence_detector'].setExplodeSentences(False)  | Info: whether to explode each sentence into a different row, for better parallelization. Defaults to false. | Currently set to : False\n","pipe['sentence_detector'].setMinLength(0)            | Info: Set the minimum allowed length for each sentence. | Currently set to : 0\n","pipe['sentence_detector'].setMaxLength(99999)        | Info: Set the maximum allowed length for each sentence | Currently set to : 99999\n",">>> pipe['document_assembler'] has settable params:\n","pipe['document_assembler'].setCleanupMode('shrink')  | Info: possible values: disabled, inplace, inplace_full, shrink, shrink_full, each, each_full, delete_full | Currently set to : shrink\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"C9z5pzjmAkFV","colab_type":"text"},"source":["### 2.2 Configure the Normalizer not to lowercase text "]},{"cell_type":"code","metadata":{"id":"L8QsX18utG_Q","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":111},"executionInfo":{"status":"ok","timestamp":1600189973937,"user_tz":-120,"elapsed":99775,"user":{"displayName":"Christian Kasim Loan","photoUrl":"","userId":"14469489166467359317"}},"outputId":"e848a7c1-e5ea-42f7-9bf0-99e0189aeb3d"},"source":["pipe['normalizer'].setLowercase(True)      \n","pipe.predict('LOWERCASE BY DEFAULT')"],"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>normalized</th>\n","      <th>sentence</th>\n","    </tr>\n","    <tr>\n","      <th>origin_index</th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>[lowercase, by, default]</td>\n","      <td>LOWERCASE BY DEFAULT</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                            normalized              sentence\n","origin_index                                                \n","0             [lowercase, by, default]  LOWERCASE BY DEFAULT"]},"metadata":{"tags":[]},"execution_count":5}]},{"cell_type":"markdown","metadata":{"id":"VlQHcW_VAfn9","colab_type":"text"},"source":["### 2.3Configure normalizer to remove strings based on regex pattern.\n","Lets remove all occurences of the lowercase letters x to z with the pattern [x-z]. "]},{"cell_type":"code","metadata":{"id":"JVXrpP7IvCR1","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":111},"executionInfo":{"status":"ok","timestamp":1600189975385,"user_tz":-120,"elapsed":101213,"user":{"displayName":"Christian Kasim Loan","photoUrl":"","userId":"14469489166467359317"}},"outputId":"ca763360-b905-4a5f-cdf6-34c933dbb2b3"},"source":["# Configure the Normalizer \n","pipe['normalizer'].setCleanupPatterns(['[x-z]']) \n","pipe.predict('From the x to the y to the z')"],"execution_count":6,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>normalized</th>\n","      <th>sentence</th>\n","    </tr>\n","    <tr>\n","      <th>origin_index</th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>[from, the, to, the, to, the]</td>\n","      <td>From the x to the y to the z</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                 normalized                      sentence\n","origin_index                                                             \n","0             [from, the, to, the, to, the]  From the x to the y to the z"]},"metadata":{"tags":[]},"execution_count":6}]},{"cell_type":"markdown","metadata":{"id":"f8h4s-dmB1D7","colab_type":"text"},"source":["#### NOTE: The regex pattern is applied **BEFORE** lowercasing.    \n","This is why the X,Y,Z tokens are kept i nthe following example\n"]},{"cell_type":"code","metadata":{"id":"C7mfz7tLzUkc","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":111},"executionInfo":{"status":"ok","timestamp":1600189977257,"user_tz":-120,"elapsed":103074,"user":{"displayName":"Christian Kasim Loan","photoUrl":"","userId":"14469489166467359317"}},"outputId":"c5b9370b-77fc-4abc-f55b-bc660de91897"},"source":["# Configure the Normalizer \n","pipe['normalizer'].setCleanupPatterns(['[x-z]']) \n","pipe.predict('From the X to the Y to the Z')"],"execution_count":7,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>normalized</th>\n","      <th>sentence</th>\n","    </tr>\n","    <tr>\n","      <th>origin_index</th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>[from, the, x, to, the, y, to, the, z]</td>\n","      <td>From the X to the Y to the Z</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                          normalized                      sentence\n","origin_index                                                                      \n","0             [from, the, x, to, the, y, to, the, z]  From the X to the Y to the Z"]},"metadata":{"tags":[]},"execution_count":7}]},{"cell_type":"markdown","metadata":{"id":"IRSEzc-RCceu","colab_type":"text"},"source":["# 3. Get one row per normalized token by setting outputlevel to token.    \n","This lets us compare what the original token was and what it was normalized to. "]},{"cell_type":"code","metadata":{"id":"9bujAZtOCfRW","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":359},"executionInfo":{"status":"ok","timestamp":1600189978980,"user_tz":-120,"elapsed":104784,"user":{"displayName":"Christian Kasim Loan","photoUrl":"","userId":"14469489166467359317"}},"outputId":"f1a8b544-9481-49d5-a21b-fddd3ae654ad"},"source":["pipe.predict('From the X to the Y to the Z', output_level='token')"],"execution_count":8,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>normalized</th>\n","      <th>token</th>\n","    </tr>\n","    <tr>\n","      <th>origin_index</th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>from</td>\n","      <td>From</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>the</td>\n","      <td>the</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>x</td>\n","      <td>X</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>to</td>\n","      <td>to</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>the</td>\n","      <td>the</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>y</td>\n","      <td>Y</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>to</td>\n","      <td>to</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>the</td>\n","      <td>the</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>z</td>\n","      <td>Z</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["             normalized token\n","origin_index                 \n","0                  from  From\n","0                   the   the\n","0                     x     X\n","0                    to    to\n","0                   the   the\n","0                     y     Y\n","0                    to    to\n","0                   the   the\n","0                     z     Z"]},"metadata":{"tags":[]},"execution_count":8}]}]}