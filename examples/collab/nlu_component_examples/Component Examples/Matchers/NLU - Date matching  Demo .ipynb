{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"NLU - Date matching  Demo .ipynb","provenance":[{"file_id":"1svpqtC3cY6JnRGeJngIPl2raqxdowpyi","timestamp":1599400881246},{"file_id":"1tW833T3HS8F5Lvn6LgeDd5LW5226syKN","timestamp":1599398724652},{"file_id":"1CYzHfQyFCdvIOVO2Z5aggVI9c0hDEOrw","timestamp":1599354735581}],"collapsed_sections":[],"authorship_tag":"ABX9TyOjQGf1OsxhrPIg3B+Llelo"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"M2-GiYL6xurJ","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1600190148373,"user_tz":-120,"elapsed":64086,"user":{"displayName":"Christian Kasim Loan","photoUrl":"","userId":"14469489166467359317"}}},"source":["import os\n","! apt-get update -qq > /dev/null   \n","# Install java\n","! apt-get install -y openjdk-8-jdk-headless -qq > /dev/null\n","os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n","os.environ[\"PATH\"] = os.environ[\"JAVA_HOME\"] + \"/bin:\" + os.environ[\"PATH\"]\n","! pip install nlu > /dev/null   \n"],"execution_count":1,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"NYQRU3pRO146","colab_type":"text"},"source":["# Date Matching\n","\n","\n","text here\n","\n"]},{"cell_type":"markdown","metadata":{"id":"Gph8XOL1Pzpl","colab_type":"text"},"source":["# NLU makes Date Matching easy. \n","\n"]},{"cell_type":"code","metadata":{"id":"pmpZSNvGlyZQ","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":111},"executionInfo":{"status":"ok","timestamp":1600190181616,"user_tz":-120,"elapsed":97319,"user":{"displayName":"Christian Kasim Loan","photoUrl":"","userId":"14469489166467359317"}},"outputId":"dcb7a528-9cf2-4f18-b30a-d2abf4afcb7f"},"source":["import nlu \n","\n","example_text =  [\"A person like Jim or Joe\", \n"," \"An organisation like Microsoft or PETA\",\n"," \"A location like Germany\",\n"," \"Anything else like Playstation\", \n"," \"Person consisting of multiple tokens like Angela Merkel or Donald Trump\",\n"," \"Organisations consisting of multiple tokens like JP Morgan\",\n"," \"Locations consiting of multiple tokens like Los Angeles\", \n"," \"Anything else made up of multiple tokens like Super Nintendo\",]\n","\n","pipe = nlu.load('match.date')\n","pipe.predict(\"Jim and Joe went to the market next to the town hall\")\n"],"execution_count":2,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>sentence</th>\n","      <th>date</th>\n","    </tr>\n","    <tr>\n","      <th>origin_index</th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Jim and Joe went to the market next to the tow...</td>\n","      <td>[]</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                                       sentence date\n","origin_index                                                        \n","0             Jim and Joe went to the market next to the tow...   []"]},"metadata":{"tags":[]},"execution_count":2}]},{"cell_type":"markdown","metadata":{"id":"if5mQWqRxDst","colab_type":"text"},"source":["## Configure the date macher with custom parameters"]},{"cell_type":"code","metadata":{"id":"j2ZZZvr1uGpx","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":488},"executionInfo":{"status":"ok","timestamp":1600190184278,"user_tz":-120,"elapsed":99971,"user":{"displayName":"Christian Kasim Loan","photoUrl":"","userId":"14469489166467359317"}},"outputId":"c69fa802-c02d-4828-d525-b18d72e42a57"},"source":["pipe.print_info()\n","# Lets set our Chunker to only match NN\n","pipe['date_matcher'].setReadMonthFirst(True)   \n","\n","# Now we can predict with the configured pipeline\n","pipe.predict(\"2020/01/01 was a intresting day\")"],"execution_count":3,"outputs":[{"output_type":"stream","text":["The following parameters are configurable for this NLU pipeline (You can copy paste the examples) :\n",">>> pipe['date_matcher'] has settable params:\n","pipe['date_matcher'].setDateFormat('yyyyMM')         | Info: desired format for dates extracted | Currently set to : yyyyMM\n","pipe['date_matcher'].setReadMonthFirst(True)         | Info: Whether to parse july 07/05/2015 or as 05/07/2015 | Currently set to : True\n","pipe['date_matcher'].setDefaultDayWhenMissing(1)     | Info: which day to set when it is missing from parsed input | Currently set to : 1\n",">>> pipe['default_tokenizer'] has settable params:\n","pipe['default_tokenizer'].setTargetPattern('\\S+')    | Info: pattern to grab from text as token candidates. Defaults \\S+ | Currently set to : \\S+\n","pipe['default_tokenizer'].setContextChars(['.', ',', ';', ':', '!', '?', '*', '-', '(', ')', '\"', \"'\"])  | Info: character list used to separate from token boundaries | Currently set to : ['.', ',', ';', ':', '!', '?', '*', '-', '(', ')', '\"', \"'\"]\n","pipe['default_tokenizer'].setCaseSensitiveExceptions(True)  | Info: Whether to care for case sensitiveness in exceptions | Currently set to : True\n","pipe['default_tokenizer'].setMinLength(0)            | Info: Set the minimum allowed legth for each token | Currently set to : 0\n","pipe['default_tokenizer'].setMaxLength(99999)        | Info: Set the maximum allowed legth for each token | Currently set to : 99999\n",">>> pipe['sentence_detector'] has settable params:\n","pipe['sentence_detector'].setUseAbbreviations(True)  | Info: whether to apply abbreviations at sentence detection | Currently set to : True\n","pipe['sentence_detector'].setDetectLists(True)       | Info: whether detect lists during sentence detection | Currently set to : True\n","pipe['sentence_detector'].setUseCustomBoundsOnly(False)  | Info: Only utilize custom bounds in sentence detection | Currently set to : False\n","pipe['sentence_detector'].setCustomBounds([])        | Info: characters used to explicitly mark sentence bounds | Currently set to : []\n","pipe['sentence_detector'].setExplodeSentences(False)  | Info: whether to explode each sentence into a different row, for better parallelization. Defaults to false. | Currently set to : False\n","pipe['sentence_detector'].setMinLength(0)            | Info: Set the minimum allowed length for each sentence. | Currently set to : 0\n","pipe['sentence_detector'].setMaxLength(99999)        | Info: Set the maximum allowed length for each sentence | Currently set to : 99999\n",">>> pipe['document_assembler'] has settable params:\n","pipe['document_assembler'].setCleanupMode('shrink')  | Info: possible values: disabled, inplace, inplace_full, shrink, shrink_full, each, each_full, delete_full | Currently set to : shrink\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>sentence</th>\n","      <th>date</th>\n","    </tr>\n","    <tr>\n","      <th>origin_index</th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>2020/01/01 was a intresting day</td>\n","      <td>[202001]</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                     sentence      date\n","origin_index                                           \n","0             2020/01/01 was a intresting day  [202001]"]},"metadata":{"tags":[]},"execution_count":3}]},{"cell_type":"code","metadata":{"id":"2z5D3cPrEhu9","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":111},"executionInfo":{"status":"ok","timestamp":1600190186542,"user_tz":-120,"elapsed":102223,"user":{"displayName":"Christian Kasim Loan","photoUrl":"","userId":"14469489166467359317"}},"outputId":"f225446b-d934-4902-a766-9ee49d4a7e08"},"source":["pipe['date_matcher'].setReadMonthFirst(False)   \n","\n","# Now we can predict with the configured pipeline\n","pipe.predict(\"2020/01/01 was a intresting day\")\n"],"execution_count":4,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>sentence</th>\n","      <th>date</th>\n","    </tr>\n","    <tr>\n","      <th>origin_index</th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>2020/01/01 was a intresting day</td>\n","      <td>[202001]</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                     sentence      date\n","origin_index                                           \n","0             2020/01/01 was a intresting day  [202001]"]},"metadata":{"tags":[]},"execution_count":4}]},{"cell_type":"code","metadata":{"id":"n3p0gLbvEodo","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1600190186545,"user_tz":-120,"elapsed":102220,"user":{"displayName":"Christian Kasim Loan","photoUrl":"","userId":"14469489166467359317"}}},"source":[""],"execution_count":4,"outputs":[]}]}