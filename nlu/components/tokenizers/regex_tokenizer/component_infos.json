{"name": "regex_tokenizer", "description": "todo", "trainable": false, "output_level": "token", "outputs": ["token"], "inputs": ["sentence"], "type": "tokenizer", "spark_input_column_names": ["sentence"], "spark_output_column_names": ["token"], "provider": "sparknlp", "license": "open source", "computation_context": "spark", "output_context": "spark"}